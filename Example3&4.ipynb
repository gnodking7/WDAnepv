{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnodking7/WDAnepv/blob/main/Example3%264.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "In this example, we use the UCI datasets Vehicle and LSVT to demonstrate the classification accuracy of WDA-nepv in comparison to those of WDA-gd [1] and WDA-eig [3].\n",
        "\n",
        "We will go over the background of the example in the following order:\n",
        "1.   What are Vehicle and LSVT datasets?\n",
        "2.   What are WDA-nepv, WDA-gd, and WDA-eig?\n",
        "3.   Example Setup\n",
        "\n",
        "### What are Vehicle and LSVT datasets?\n",
        "UCI Machine Learning Repository is a collection of datasets that are widely used by the machine learning community for the empirical analysis of machine learning algorithms. In particular, the repository provides a wide variety of datasets that are suitable for clustering and classification tasks. \n",
        "\n",
        "Among the datasets, we choose the real-life datasets named Vehicle and LSVT. Vehicle dataset consists of 2D silhouette images of four types of vehicle. LSVT is a dataset consisting of phonations of Parkinson's disease subjects who participated in a voice rehabilitation treatment. LSVT dataset is suitable for a binary class classification problem as the classes correspond to 'acceptable' and 'unacceptable' phonations. Vehicle dataset has 4 classes with a total number of 946 data points of dimension 18 and LSVT dataset has 2 classes with a total number of 126 data points of dimension 309."
      ],
      "metadata": {
        "id": "qZV7MbvJE9Le"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S_I1mu5J9Cau"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaIlaxjq9QZa",
        "outputId": "a7d8330e-91a5-4b59-a34f-0da29dd677ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymanopt\n",
            "  Downloading pymanopt-2.0.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from pymanopt) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from pymanopt) (1.21.6)\n",
            "Installing collected packages: pymanopt\n",
            "Successfully installed pymanopt-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (1.5)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from autograd) (1.21.6)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymanopt\n",
        "!pip install autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c9phm60E9TGN"
      },
      "outputs": [],
      "source": [
        "import WDA_datasets as datasets\n",
        "import WDAnepv\n",
        "import WDAgd\n",
        "import WDAeig\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cHKUc77RMVSS"
      },
      "outputs": [],
      "source": [
        "# Call KNN package\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Set parameters\n",
        "reg = 0.01  # regularization parameter\n",
        "e = 1 # perturbation parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are WDA-nepv, WDA-gd, and WDA-eig?\n",
        "WDA-nepv, WDA-gd, and WDA-eig are algorithms that solves Wasserstein Discriminant Analysis (WDA) [1]:\n",
        "$$\\max_{\\mathbf{P}^T\\mathbf{P}=I_p}\\frac{\\mbox{tr}(\\mathbf{P}^T\\mathbf{C}_b(\\mathbf{P})\\mathbf{P})}{\\mbox{tr}(\\mathbf{P}^T\\mathbf{C}_w(\\mathbf{P})\\mathbf{P})}$$\n",
        "where $\\mathbf{C}_b(\\mathbf{P})$ and $\\mathbf{C}_w(\\mathbf{P})$\n",
        "are defined as the between and within cross-covariance matrices\n",
        "$$\\mathbf{C}_b(\\mathbf{P}_k) = \\sum_{c,c'>c}  \\sum_{ij}{T}_{ij}^{c,c'}(\\mathbf{P}_k)(\\mathbf{x}_i^c-\\mathbf{x}_j^{c'})(\\mathbf{x}_i^c-\\mathbf{x}_j^{c'})^T$$\n",
        "$$\\mathbf{C}_w(\\mathbf{P}_k) = \\sum_c  \\sum_{ij}{T}_{ij}^{c,c}(\\mathbf{P}_k)(\\mathbf{x}_i^c-\\mathbf{x}_j^{c})(\\mathbf{x}_i^c-\\mathbf{x}_j^{c})^T $$\n",
        "The matrices $\\mathbf{T}^{c,c'}$ and $\\mathbf{T}^{c,c}$ are transport matrices and can be computed using Acc_SK.\n",
        "\n",
        "WDA-gd is a steepest-descent algorithm and incurs extra costs for computing the gradients. WDA-eig solves a nonlinear generalized eigenvalue problem associated with an approximate problem to WDA.\n",
        "\n",
        "WDA-nepvs is gradient-free and makes no approximation to WDA. In a nutshell, WDA-nepv can be described as an algorithm that iteratively updates the projection matrix $\\mathbf{P}_k$ by \n",
        "$$\\mathbf{P}_{k+1} = \\mbox{argmax}_{\\mathbf{P}^T\\mathbf{P}=I_p}\n",
        "\\frac{\\mbox{tr}(\\mathbf{P}^T\\mathbf{C}_b(\\mathbf{P}_k)\\mathbf{P})}\n",
        "{\\mbox{tr}(\\mathbf{P}^T\\mathbf{C}_w(\\mathbf{P}_k)\\mathbf{P})}$$\n",
        "which, as a standard trace ratio problem, can be solved by the Self-Consistent-Field (SCF) method [2]."
      ],
      "metadata": {
        "id": "PCxzluqLGJvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Setup\n",
        "As a supervised linear dimensionality reduction method, WDA seeks an optimal projection such that the class structure of the projected data vectors becomes more pronounced. For this reason, the effectiveness of WDA is measured by the classification accuracy.\n",
        "\n",
        "Following the standard practice in classification tasks, each dataset is divided into the training dataset and the testing dataset. In this example, we consider 50% training and 50% testing split. After the algorithm is trained on the training dataset and an optimal projection matrix $\\mathbf{P}$ is obtained, the testing dataset is then projected onto a lower dimensional subspace using this projection $\\mathbf{P}$. Then, the classification accuracy of the algorithm is measured by using K-Nearest-Neighbors classifier (KNN) on the projected testing dataset. \n",
        "\n",
        "Two different experiments are considered:\n",
        "\n",
        "\n",
        "*   With fixed subspace dimension $p=5$, various KNN neighbors $K\\in\\{1,3,5,7,9,11,13,15,17,19\\}$ are considered. \n",
        "*   With fixed KNN neighbors $K=11$, various subspace dimension $p\\in\\{1,2,3,4,5\\}$ for Vehicle dataset and $p\\in\\{5,10,15,20,25\\}$ for LSVT dataset are considered.\n",
        "\n",
        "The regularization parameter $\\lambda=0.01$ is fixed throughout and the stopping tolerance parameter is set at $10^{-5}$. Initial projection matrix $\\mathbf{P}_0$ is randomly chosen. All classification results are averaged over 20 trials."
      ],
      "metadata": {
        "id": "NPOvd0ipGcPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCstgiu4MdB4"
      },
      "outputs": [],
      "source": [
        "# Vehicle dataset\n",
        "n_trial = 20\n",
        "# Dict of success rate\n",
        "Acclist_gd, Acclist_eig, Acclist_nepv = dict(), dict(), dict()\n",
        "# List of running time\n",
        "Time_gd, Time_eig, Time_nepv = [], [], []\n",
        "\n",
        "# Trials\n",
        "for i in range(n_trial):\n",
        "    print('Starting Trial #:', i)\n",
        "\n",
        "    TR, TR_L, TST, TST_L = datasets.load_uci('vehicle')\n",
        "    d = TR.shape[1]\n",
        "\n",
        "    time_gd, time_eig, time_nepv = [], [], []\n",
        "\n",
        "    # For various subspace dimension p\n",
        "    for p in [1, 2, 3, 4, 5]:\n",
        "        acclist_gd, acclist_eig, acclist_nepv = [], [], []\n",
        "        x0 = np.random.randn(d, p)\n",
        "        P0, r = np.linalg.qr(x0) # random initial projection\n",
        "\n",
        "        start1 = time.time()\n",
        "        Pgd, proj1, Itr1, PROJ1 = WDAgd.wda_gd(TR, TR_L, p, reg, P0)    # WDAgd\n",
        "        end1 = time.time()\n",
        "        time1 = end1 - start1\n",
        "        time_gd.append(time1)\n",
        "\n",
        "        start2 = time.time()\n",
        "        Peig, proj2, WDA_Val2, PROJ2, Sub_Err2 = WDAeig.wda_eig(TR, TR_L, p, reg, P0, Breg=e)   # WDAeig\n",
        "        end2 = time.time()\n",
        "        time2 = end2 - start2\n",
        "        time_eig.append(time2)\n",
        "\n",
        "        start3 = time.time()\n",
        "        Pnepv, proj3, WDA_Val3, PROJ3, Sub_Err3 = WDAnepv.wda_nepv(TR, TR_L, p, reg, P0, Breg=e, tol=1e-5)  # WDAnepv\n",
        "        end3 = time.time()\n",
        "        time3 = end3 - start3\n",
        "        time_nepv.append(time3)\n",
        "\n",
        "        # For various KNN neighbors\n",
        "        for K in [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]:\n",
        "            # KNN models\n",
        "            model1 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model1.fit(proj1(TR), TR_L)\n",
        "            model2 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model2.fit(proj2(TR), TR_L)\n",
        "            model3 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model3.fit(proj3(TR), TR_L)\n",
        "\n",
        "            # Test\n",
        "            predicted1 = model1.predict(proj1(TST))\n",
        "            acc1 = accuracy_score(TST_L, predicted1)\n",
        "            predicted2 = model2.predict(proj2(TST))\n",
        "            acc2 = accuracy_score(TST_L, predicted2)\n",
        "            predicted3 = model3.predict(proj3(TST))\n",
        "            acc3 = accuracy_score(TST_L, predicted3)\n",
        "\n",
        "            # Store accuracy for each K\n",
        "            acclist_gd.append(acc1)\n",
        "            acclist_eig.append(acc2)\n",
        "            acclist_nepv.append(acc3)\n",
        "\n",
        "        # Store accuracy for each p\n",
        "        if p not in Acclist_gd:\n",
        "            Acclist_gd[p] = []\n",
        "        if p not in Acclist_eig:\n",
        "            Acclist_eig[p] = []\n",
        "        if p not in Acclist_nepv:\n",
        "            Acclist_nepv[p] = []\n",
        "        Acclist_gd[p].append(acclist_gd)\n",
        "        Acclist_eig[p].append(acclist_eig)\n",
        "        Acclist_nepv[p].append(acclist_nepv)\n",
        "\n",
        "    # Store running time    \n",
        "    Time_gd.append(time_gd)\n",
        "    Time_eig.append(time_eig)\n",
        "    Time_nepv.append(time_nepv)\n",
        "\n",
        "avg_gd, avg_eig, avg_nepv = [], [], []\n",
        "for p in [1, 2, 3, 4, 5]:\n",
        "    avg_gd.append(np.mean(Acclist_gd[p], 0))\n",
        "    avg_eig.append(np.mean(Acclist_eig[p], 0))\n",
        "    avg_nepv.append(np.mean(Acclist_nepv[p], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXaZojw0-v52"
      },
      "outputs": [],
      "source": [
        "# Call KNN package\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Load UCI datasets\n",
        "Veh_TR, Veh_TR_L, Veh_TST, Veh_TST_L = datasets.load_uci('vehicle')\n",
        "LSVT_TR, LSVT_TR_L, LSVT_TST, LSVT_TST_L = datasets.load_uci('lsvt')\n",
        "\n",
        "reg = 0.01  # regularization parameter\n",
        "e = 1 # perturbation parameter\n",
        "\n",
        "n_trial = 20\n",
        "# Dict of success rate\n",
        "Acclist_gd, Acclist_eig, Acclist_nepv = dict(), dict(), dict()\n",
        "# List of running time\n",
        "Time_gd, Time_eig, Time_nepv = [], [], []\n",
        "\n",
        "# Trials for LSVT\n",
        "d = LSVT_TR.shape[1] # dimension size\n",
        "TR, TR_L, TST, TST_L = LSVT_TR, LSVT_TR_L, LSVT_TST, LSVT_TST_L\n",
        "for i in range(n_trial):\n",
        "    print(i)\n",
        "\n",
        "    time_gd, time_eig, time_nepv = [], [], []\n",
        "\n",
        "    # For various subspace dimension p\n",
        "    for p in [5, 10, 15, 20, 25]:\n",
        "        acclist_gd, acclist_eig, acclist_nepv = [], [], []\n",
        "        x0 = np.random.randn(d, p)\n",
        "        P0, r = np.linalg.qr(x0) # random initial projection\n",
        "\n",
        "        start1 = time.time()\n",
        "        Pgd, proj1, Itr1, PROJ1 = WDAgd.wda_gd(TR, TR_L, p, reg, P0)    # WDAgd\n",
        "        end1 = time.time()\n",
        "        time1 = end1 - start1\n",
        "        time_gd.append(time1)\n",
        "\n",
        "        start2 = time.time()\n",
        "        Peig, proj2, WDA_Val2, PROJ2, Sub_Err2 = WDAeig.wda_eig(TR, TR_L, p, reg, P0, Breg=e)   # WDAeig\n",
        "        end2 = time.time()\n",
        "        time2 = end2 - start2\n",
        "        time_eig.append(time2)\n",
        "\n",
        "        start3 = time.time()\n",
        "        Pnepv, proj3, WDA_Val3, PROJ3, Sub_Err3 = WDAnepv.wda_nepv(TR, TR_L, p, reg, P0, Breg=e, tol=1e-5)  # WDAnepv\n",
        "        end3 = time.time()\n",
        "        time3 = end3 - start3\n",
        "        time_nepv.append(time3)\n",
        "\n",
        "        # For various KNN neighbors\n",
        "        for K in [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]:\n",
        "            # KNN models\n",
        "            model1 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model1.fit(proj1(TR), TR_L)\n",
        "            model2 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model2.fit(proj2(TR), TR_L)\n",
        "            model3 = KNeighborsClassifier(n_neighbors=K)\n",
        "            model3.fit(proj3(TR), TR_L)\n",
        "\n",
        "            # Test\n",
        "            predicted1 = model1.predict(proj1(TST))\n",
        "            acc1 = accuracy_score(TST_L, predicted1)\n",
        "            predicted2 = model2.predict(proj2(TST))\n",
        "            acc2 = accuracy_score(TST_L, predicted2)\n",
        "            predicted3 = model3.predict(proj3(TST))\n",
        "            acc3 = accuracy_score(TST_L, predicted3)\n",
        "\n",
        "            # Store accuracy for each K\n",
        "            acclist_gd.append(acc1)\n",
        "            acclist_eig.append(acc2)\n",
        "            acclist_nepv.append(acc3)\n",
        "\n",
        "        # Store accuracy for each p\n",
        "        if p not in Acclist_gd:\n",
        "            Acclist_gd[p] = []\n",
        "        if p not in Acclist_eig:\n",
        "            Acclist_eig[p] = []\n",
        "        if p not in Acclist_nepv:\n",
        "            Acclist_nepv[p] = []\n",
        "        Acclist_gd[p].append(acclist_gd)\n",
        "        Acclist_eig[p].append(acclist_eig)\n",
        "        Acclist_nepv[p].append(acclist_nepv)\n",
        "\n",
        "    # Store running time    \n",
        "    Time_gd.append(time_gd)\n",
        "    Time_eig.append(time_eig)\n",
        "    Time_nepv.append(time_nepv)\n",
        "\n",
        "avg_gd, avg_eig, avg_nepv = [], [], []\n",
        "for p in [5, 10, 15, 20, 25]:\n",
        "    avg_gd.append(np.mean(Acclist_gd[p], 0))\n",
        "    avg_eig.append(np.mean(Acclist_eig[p], 0))\n",
        "    avg_nepv.append(np.mean(Acclist_nepv[p], 0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CBgDnuoCc88cbTf8XDHysvAhnr5TltA7",
      "authorship_tag": "ABX9TyORo2jY7U3MN7EKiOD/92je",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}